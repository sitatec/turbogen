{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0673e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd015f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install uv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820a678b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/sitatec/LightX2V.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ed51ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "%uv pip install ./LightX2V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f95a2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python LightX2V/tools/convert/converter.py \\\n",
    "    --source _model_weights/Qwen-Image-2512-Lightning/transformer/ \\\n",
    "    --output _model_weights/Qwen-Image-2512/int8/ \\\n",
    "    --output_ext .safetensors \\\n",
    "    --output_name Qwen-Image-2512-Lightning-INT8 \\\n",
    "    --model_type qwen_image_dit \\\n",
    "    --lora_path _model_weights/Qwen-Image-2512-Lightning/lora/Qwen-Image-2512-Lightning-4steps-V1.0-bf16.safetensors \\\n",
    "    --lora_strength 1.0 \\\n",
    "    --device cuda \\\n",
    "    --quantized \\\n",
    "    --linear_type int8 \\\n",
    "    --non_linear_dtype torch.bfloat16 \\\n",
    "    --single_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc527ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python LightX2V/tools/convert/converter.py \\\n",
    "    --source _model_weights/Qwen-Image-Edit-2511-Lightning/transformer/ \\\n",
    "    --output _model_weights/Qwen-Image-Edit-2511-Lightning/int8/ \\\n",
    "    --output_ext .safetensors \\\n",
    "    --output_name Qwen-Image-Edit-2511-Lightning-INT8 \\\n",
    "    --model_type qwen_image_dit \\\n",
    "    --lora_path _model_weights/Qwen-Image-Edit-2511-Lightning/lora/Qwen-Image-Edit-2511-Lightning-4steps-V1.0-bf16.safetensors \\\n",
    "    --lora_strength 1.0 \\\n",
    "    --device cuda \\\n",
    "    --quantized \\\n",
    "    --linear_type int8 \\\n",
    "    --non_linear_dtype torch.bfloat16 \\\n",
    "    --single_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3793ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python LightX2V/tools/convert/converter.py \\\n",
    "    --source _model_weights/Qwen-Image-2512/transformer/ \\\n",
    "    --output _model_weights/Qwen-Image-2512/fp8/ \\\n",
    "    --output_ext .safetensors \\\n",
    "    --output_name Qwen-Image-2512-FP8 \\\n",
    "    --model_type qwen_image_dit \\\n",
    "    --device cuda \\\n",
    "    --quantized \\\n",
    "    --linear_type fp8 \\\n",
    "    --non_linear_dtype torch.bfloat16 \\\n",
    "    --single_file"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
