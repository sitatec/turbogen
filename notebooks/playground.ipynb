{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "901b58f3",
      "metadata": {},
      "outputs": [],
      "source": [
        "%cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf3cf239",
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install uv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e5112f2e",
      "metadata": {},
      "outputs": [],
      "source": [
        "!uv pip install -r requirements.txt --system"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "47bb28e0",
      "metadata": {},
      "outputs": [],
      "source": [
        "from typing import Literal\n",
        "from download_models import download_qwen_models, download_zimage_models, download_wan22_models\n",
        "\n",
        "SELECTED: Literal[\"qwen-image-edit\", \"qwen-image\", \"zimage-turbo\", \"wan22-i2v\", \"wan22-t2v\"] = \"qwen-image-edit\"\n",
        "\n",
        "qwen_image_edit_path, qwen_image_path, zimage_turbo_path, wan22_i2v_path, wan22_t2v_path = None, None, None, None, None\n",
        "\n",
        "if SELECTED.startswith(\"qwen\"):\n",
        "  qwen_image_edit_path, qwen_image_path = download_qwen_models()\n",
        "elif SELECTED.startswith(\"zimage\"):\n",
        "  zimage_turbo_path = download_zimage_models()\n",
        "elif SELECTED.startswith(\"wan22\"):\n",
        "  wan22_i2v_path, wan22_t2v_path = download_wan22_models()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2d497ec0",
      "metadata": {},
      "outputs": [],
      "source": [
        "import ctypes\n",
        "\n",
        "try:\n",
        "    ctypes.CDLL(\"libcuda.so.1\", mode=ctypes.RTLD_GLOBAL)\n",
        "    print(\"✅ Successfully loaded real CUDA driver (libcuda.so.1)\")\n",
        "except OSError:\n",
        "    print(\"⚠️ WARNING: Could not load libcuda.so.1 manually.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c59f71c",
      "metadata": {},
      "outputs": [],
      "source": [
        "from models.lightx2v_models import QwenImage, QwenImageEdit, ZImageTurbo, Wan22\n",
        "\n",
        "if SELECTED == \"qwen-image-edit\":\n",
        "  gen_type = \"i2i\"\n",
        "  model = QwenImageEdit(model_path=str(qwen_image_edit_path))\n",
        "elif SELECTED == \"qwen-image\":\n",
        "  gen_type = \"t2i\"\n",
        "  model = QwenImage(model_path=str(qwen_image_path))\n",
        "elif SELECTED == \"zimage-turbo\":\n",
        "  gen_type = \"t2i\"\n",
        "  model = ZImageTurbo(model_path=str(zimage_turbo_path))\n",
        "else:\n",
        "  gen_type = \"t2v\" if SELECTED == \"wan22-t2v\" else \"i2v\"\n",
        "  model = Wan22(\n",
        "    model_path=str(wan22_i2v_path if gen_type == \"i2v\" else wan22_t2v_path), \n",
        "    generation_type=gen_type, \n",
        "    quant_scheme=\"fp8-sgl\",\n",
        "    text_encoder_quantized=True,\n",
        "  )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6553945b",
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import requests\n",
        "\n",
        "def download_image(image_url: str, output_path: str, override=False):\n",
        "  if Path(output_path).exists() and not override:\n",
        "    return\n",
        "\n",
        "  response = requests.get(image_url)\n",
        "  response.raise_for_status()\n",
        "  with open(output_path, \"wb\") as f:\n",
        "    f.write(response.content)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f21c9316",
      "metadata": {},
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "from IPython.display import Video, display\n",
        "from utils import image_tensor_to_pil, save_video_tensor\n",
        "\n",
        "input_image_path_1 = \"img_in_1\"\n",
        "output =\"img_out.png\"\n",
        "\n",
        "is_video = gen_type.endswith(\"v\")\n",
        "    \n",
        "support_input_img = gen_type in [\"i2i\", \"i2v\", \"i2v\"]\n",
        "if support_input_img:\n",
        "  download_image(\n",
        "    \"https://plus.unsplash.com/premium_photo-1690407617542-2f210cf20d7e?fm=jpg&q=60&w=3000&ixlib=rb-4.1.0&ixid=M3wxMjA3fDB8MHxzZWFyY2h8MXx8cGVyc29ufGVufDB8fDB8fHww\",\n",
        "    input_image_path_1,\n",
        "  )\n",
        "\n",
        "t = time.perf_counter()\n",
        "output = model.generate(\n",
        "  prompt=\"Make this person look like a robot\",\n",
        "  image_paths=[input_image_path_1] if support_input_img else [],\n",
        "  aspect_ratio=\"1:1\",\n",
        "  resolution=\"1K\",\n",
        "  seed=9999,\n",
        ")\n",
        "print(f\"Generated in {time.perf_counter() - t:.2f}s\")\n",
        "\n",
        "assert output is not None, \"Oops, something went wrong\"\n",
        "\n",
        "if is_video:\n",
        "    output_path = \"video.mp4\"\n",
        "    save_video_tensor(output, output_path, fps=16)\n",
        "    display(Video(output, embed=True))\n",
        "else:\n",
        "    display(image_tensor_to_pil(output))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
