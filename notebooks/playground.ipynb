{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "901b58f3",
      "metadata": {},
      "outputs": [],
      "source": [
        "%cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf3cf239",
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install uv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e5112f2e",
      "metadata": {},
      "outputs": [],
      "source": [
        "!uv pip install -r requirements.txt --system"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "47bb28e0",
      "metadata": {},
      "outputs": [],
      "source": [
        "from typing import Literal\n",
        "from model_downloads import download_qwen_models, download_zimage_models, download_wan22_models\n",
        "\n",
        "SELECTED: Literal[\"qwen-image-edit\", \"qwen-image\", \"zimage-turbo\", \"wan22-i2v\", \"wan22-t2v\"] = \"qwen-image-edit\"\n",
        "\n",
        "qwen_image_edit_path, qwen_image_path, zimage_turbo_path, wan22_i2v_path, wan22_t2v_path = None, None, None, None, None\n",
        "\n",
        "if SELECTED.startswith(\"qwen\"):\n",
        "  qwen_image_edit_path, qwen_image_path = download_qwen_models()\n",
        "elif SELECTED.startswith(\"zimage\"):\n",
        "  zimage_turbo_path = download_zimage_models()\n",
        "elif SELECTED.startswith(\"wan22\"):\n",
        "  wan22_i2v_path, wan22_t2v_path = download_wan22_models()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2d497ec0",
      "metadata": {},
      "outputs": [],
      "source": [
        "import ctypes\n",
        "\n",
        "try:\n",
        "    ctypes.CDLL(\"libcuda.so.1\", mode=ctypes.RTLD_GLOBAL)\n",
        "    print(\"✅ Successfully loaded real CUDA driver (libcuda.so.1)\")\n",
        "except OSError:\n",
        "    print(\"⚠️ WARNING: Could not load libcuda.so.1 manually.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c59f71c",
      "metadata": {},
      "outputs": [],
      "source": [
        "from models.lightx2v_models import QwenImageLite, QwenImageEditLite, ZImageTurbo, Wan22Lite\n",
        "\n",
        "if SELECTED == \"qwen-image-edit\":\n",
        "  gen_type = \"i2i\"\n",
        "  model = QwenImageEditLite(model_path=str(qwen_image_edit_path))\n",
        "elif SELECTED == \"qwen-image\":\n",
        "  gen_type = \"t2i\"\n",
        "  model = QwenImageLite(model_path=str(qwen_image_path))\n",
        "elif SELECTED == \"zimage-turbo\":\n",
        "  gen_type = \"t2i\"\n",
        "  model = ZImageTurbo(model_path=str(zimage_turbo_path))\n",
        "else:\n",
        "  gen_type = \"t2v\" if SELECTED == \"wan22-t2v\" else \"i2v\"\n",
        "  model = Wan22Lite(\n",
        "    model_path=str(wan22_i2v_path if gen_type == \"i2v\" else wan22_t2v_path), \n",
        "    generation_type=gen_type, \n",
        "    quant_scheme=\"fp8-sgl\",\n",
        "    text_encoder_quantized=True,\n",
        "  )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6553945b",
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import requests\n",
        "\n",
        "def download_image(image_url: str, output_path: str, override=False):\n",
        "  if Path(output_path).exists() and not override:\n",
        "    return\n",
        "\n",
        "  response = requests.get(image_url)\n",
        "  response.raise_for_status()\n",
        "  with open(output_path, \"wb\") as f:\n",
        "    f.write(response.content)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f21c9316",
      "metadata": {},
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "from IPython.display import Video, display\n",
        "from core.utils import image_tensor_to_pil, save_video_tensor\n",
        "\n",
        "input_image_path_1 = \"img_in_1\"\n",
        "output =\"img_out.png\"\n",
        "\n",
        "is_video = gen_type.endswith(\"v\")\n",
        "    \n",
        "support_input_img = gen_type in [\"i2i\", \"i2v\", \"i2v\"]\n",
        "if support_input_img:\n",
        "  download_image(\n",
        "    \"https://plus.unsplash.com/premium_photo-1690407617542-2f210cf20d7e?fm=jpg&q=60&w=3000&ixlib=rb-4.1.0&ixid=M3wxMjA3fDB8MHxzZWFyY2h8MXx8cGVyc29ufGVufDB8fDB8fHww\",\n",
        "    input_image_path_1,\n",
        "  )\n",
        "\n",
        "t = time.perf_counter()\n",
        "output = model.generate(\n",
        "  prompt=\"Make this person look like a robot\",\n",
        "  image_paths=[input_image_path_1] if support_input_img else [],\n",
        "  aspect_ratio=\"1:1\",\n",
        "  resolution=\"1K\",\n",
        "  seed=9999,\n",
        ")\n",
        "print(f\"Generated in {time.perf_counter() - t:.2f}s\")\n",
        "\n",
        "assert output is not None, \"Oops, something went wrong\"\n",
        "\n",
        "if is_video:\n",
        "    output_path = \"video.mp4\"\n",
        "    save_video_tensor(output, output_path, fps=16)\n",
        "    display(Video(output, embed=True))\n",
        "else:\n",
        "    display(image_tensor_to_pil(output))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c74c1a6d",
      "metadata": {},
      "source": [
        "---\n",
        "### Media Scoring\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b9e756d7",
      "metadata": {},
      "outputs": [],
      "source": [
        "from typing import Literal\n",
        "import time\n",
        "from core.services.media_scoring import ImageScorer, VideoScorer\n",
        "from model_downloads import download_image_scorer, download_video_scorer\n",
        "\n",
        "scoring_typ: Literal[\"video\", \"image\"] = \"video\"\n",
        "\n",
        "t = time.perf_counter()\n",
        "if scoring_typ == \"video\":\n",
        "  scorer = VideoScorer(download_video_scorer())\n",
        "else:\n",
        "  scorer = ImageScorer(download_image_scorer())\n",
        "print(f\"Scorer loaded in {time.perf_counter() - t:.2f}s\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b6c3773b",
      "metadata": {},
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "t = time.perf_counter()\n",
        "scores = scorer.score([\"videotest.mp4\"])\n",
        "print(f\"Scores: {scores}\")\n",
        "print(f\"Scored in {time.perf_counter() - t:.2f}s\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "444eb72c",
      "metadata": {},
      "source": [
        "#### Score grid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "afb2b62c",
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import base64\n",
        "import mimetypes\n",
        "\n",
        "from IPython.display import HTML, display\n",
        "import gc\n",
        "import torch\n",
        "\n",
        "def free_mem():\n",
        "    for _ in range(3):\n",
        "        torch.cuda.empty_cache()\n",
        "        gc.collect()\n",
        "        time.sleep(0.2)\n",
        "\n",
        "if scoring_typ == \"video\":\n",
        "    video_dir = Path(\".\")\n",
        "    video_paths = sorted(\n",
        "        list(video_dir.glob(\"*.mp4\")) +\n",
        "        list(video_dir.glob(\"*.webm\"))\n",
        "    )\n",
        "\n",
        "    items_html = {}\n",
        "    torch.cuda.reset_peak_memory_stats()\n",
        "\n",
        "    for path in video_paths:\n",
        "        free_mem()\n",
        "        score = scorer.score([str(path)], fps=16)[0]\n",
        "        free_mem()\n",
        "\n",
        "        mime_type, _ = mimetypes.guess_type(path)\n",
        "        if mime_type is None:\n",
        "            continue\n",
        "\n",
        "        video_bytes = path.read_bytes()\n",
        "        video_b64 = base64.b64encode(video_bytes).decode(\"utf-8\")\n",
        "\n",
        "        items_html[score] = f\"\"\"\n",
        "        <div style=\"display:flex; flex-direction:column; align-items:center;\">\n",
        "            <video\n",
        "                controls\n",
        "                style=\"max-height:400px; width:100%; object-fit:contain;\"\n",
        "            >\n",
        "                <source src=\"data:{mime_type};base64,{video_b64}\" type=\"{mime_type}\">\n",
        "            </video>\n",
        "            <div style=\"margin-top:6px; font-weight:600;\">\n",
        "                Score: {score:.4f}\n",
        "            </div>\n",
        "        </div>\n",
        "        \"\"\"\n",
        "\n",
        "    peak_alloc = torch.cuda.max_memory_allocated()\n",
        "    peak_reserved = torch.cuda.max_memory_reserved()\n",
        "\n",
        "    print(f\"Peak allocated: {peak_alloc / 1024**2:.1f} MB\")\n",
        "    print(f\"Peak reserved:  {peak_reserved / 1024**2:.1f} MB\")\n",
        "    \n",
        "    items_html = dict(\n",
        "        sorted(items_html.items(), key=lambda item: item[0], reverse=True)\n",
        "     )\n",
        "\n",
        "    grid_html = f\"\"\"\n",
        "    <div style=\"\n",
        "        display:grid;\n",
        "        grid-template-columns: repeat(3, 1fr);\n",
        "        gap:16px;\n",
        "    \">\n",
        "        {''.join(items_html.values())}\n",
        "    </div>\n",
        "    \"\"\"\n",
        "\n",
        "    display(HTML(grid_html))\n",
        "else:\n",
        "    image_dir = Path(\".\")\n",
        "    image_paths = sorted(\n",
        "        list(image_dir.glob(\"*.jpg\")) +\n",
        "        list(image_dir.glob(\"*.jpeg\")) +\n",
        "        list(image_dir.glob(\"*.png\")) +\n",
        "        list(image_dir.glob(\"*.webp\"))\n",
        "    )\n",
        "\n",
        "    items_html = {}\n",
        "    torch.cuda.reset_peak_memory_stats()\n",
        "\n",
        "    for path in image_paths:\n",
        "        free_mem()\n",
        "        score = scorer.score([str(path)])[0]\n",
        "        free_mem()\n",
        "\n",
        "        mime_type, _ = mimetypes.guess_type(path)\n",
        "        if mime_type is None:\n",
        "            continue\n",
        "\n",
        "        image_bytes = path.read_bytes()\n",
        "        image_b64 = base64.b64encode(image_bytes).decode(\"utf-8\")\n",
        "\n",
        "        items_html[score] = f\"\"\"\n",
        "        <div style=\"display:flex; flex-direction:column; align-items:center;\">\n",
        "            <img\n",
        "                src=\"data:{mime_type};base64,{image_b64}\"\n",
        "                style=\"max-height:400px; width:100%; object-fit:contain;\"\n",
        "            />\n",
        "            <div style=\"margin-top:6px; font-weight:600;\">\n",
        "                Score: {score:.4f}\n",
        "            </div>\n",
        "        </div>\n",
        "        \"\"\"\n",
        "\n",
        "    peak_alloc = torch.cuda.max_memory_allocated()\n",
        "    peak_reserved = torch.cuda.max_memory_reserved()\n",
        "\n",
        "    print(f\"Peak allocated: {peak_alloc / 1024**2:.1f} MB\")\n",
        "    print(f\"Peak reserved:  {peak_reserved / 1024**2:.1f} MB\")\n",
        "    \n",
        "    items_html = dict(\n",
        "        sorted(items_html.items(), key=lambda item: item[0], reverse=True)\n",
        "     )\n",
        "    \n",
        "    grid_html = f\"\"\"\n",
        "    <div style=\"\n",
        "        display:grid;\n",
        "        grid-template-columns: repeat(3, 1fr);\n",
        "        gap:16px;\n",
        "    \">\n",
        "        {''.join(items_html.values())}\n",
        "    </div>\n",
        "    \"\"\"\n",
        "\n",
        "    display(HTML(grid_html))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
