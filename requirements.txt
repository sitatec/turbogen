#gptqmodel/bitsandbytes/auto-roung  # depending on env (e.g. auto-round/bitsandbytes on zero-gpu spaces, gptqmodel preferred where compatible)
#optimum  # you also need optimum if you are using auto-round or gptqmodel
torch==2.9.1
opencv-python-headless
Pillow
numpy
fast-thumbhash
aiohttp
diffusers
torchao
transformers<5.0.0 # The latest version of gptqmodel(5.6.12) isn't compatible with transformers 5.0.0 
accelerate
hf-transfer
huggingface-hub
timm
piexif
sgl-kernel
triton
kernels
flashinfer
decord
git+https://github.com/sitatec/LightX2V.git@torch2.9.1-int8-sgl-fixed 